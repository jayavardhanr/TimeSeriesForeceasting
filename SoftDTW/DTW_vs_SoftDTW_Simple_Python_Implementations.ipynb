{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('distance', 17.40784575188877)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from math import exp, log\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(5, 4)\n",
    "Z = rng.randn(6, 4)\n",
    "\n",
    "def dtw(x, y, dist):\n",
    "    \"\"\"\n",
    "    Computes Dynamic Time Warping (DTW) of two sequences.\n",
    "    :param array x: N1*M array\n",
    "    :param array y: N2*M array\n",
    "    :param func dist: distance used as cost measure\n",
    "    Returns the minimum distance, the cost matrix, the accumulated cost matrix, and the wrap path.\n",
    "    \"\"\"\n",
    "    assert len(x)\n",
    "    assert len(y)\n",
    "    r, c = len(x), len(y)\n",
    "    D0 = np.zeros((r + 1, c + 1))\n",
    "    D0[0, 1:] = np.inf\n",
    "    D0[1:, 0] = np.inf\n",
    "    D1 = D0[1:, 1:] # view\n",
    "    \n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            D1[i, j] = dist(x[i].reshape(1,-1), y[j].reshape(1,-1))\n",
    "    C = D1.copy()\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            D1[i, j] += min(D0[i, j], D0[i, j+1], D0[i+1, j])\n",
    "    return D1[-1, -1] , C, D1\n",
    "\n",
    "\n",
    "dist=lambda a,b: np.linalg.norm(a-b)\n",
    "values=dtw(X,Z,dist=dist)\n",
    "distance=values[0]\n",
    "D=values[2]\n",
    "print('distance',distance)\n",
    "#D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.407842802833436\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from math import exp, log\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def _softmin3( a, b, c,gamma):\n",
    "    a /= -gamma\n",
    "    b /= -gamma\n",
    "    c /= -gamma\n",
    "    max_val = max(max(a, b), c)\n",
    "    tmp = 0\n",
    "    tmp += exp(a - max_val)\n",
    "    tmp += exp(b - max_val)\n",
    "    tmp += exp(c - max_val)\n",
    "    return -gamma * (log(tmp) + max_val)\n",
    "\n",
    "def _soft_dtw(D,R,gamma):\n",
    "    m = D.shape[0]\n",
    "    n = D.shape[1]\n",
    "    for i in range(m + 1):\n",
    "        R[i, 0] = np.inf\n",
    "    for j in range(n + 1):\n",
    "        R[0, j] = np.inf\n",
    "        \n",
    "    R[0, 0] = 0\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            R[i, j] = D[i-1, j-1] + _softmin3(R[i-1, j], R[i-1, j-1],R[i, j-1],gamma)\n",
    "\n",
    "def SoftDTW(D, gamma=1.0):\n",
    "    m, n = D.shape\n",
    "    R_ = np.zeros((m+2, n+2), dtype=np.float64)\n",
    "    _soft_dtw(D, R_, gamma=gamma)\n",
    "    return R_[m, n],R_\n",
    "\n",
    "\n",
    "D = euclidean_distances(X, Z)\n",
    "value = SoftDTW(D, gamma=0.01)\n",
    "print(value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
